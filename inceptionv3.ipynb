{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports \nimport numpy as np \nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nimport shutil\n\nfrom glob import glob \nfrom shutil import copy\nfrom keras import layers, models\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.core import Dense, Flatten, Dropout, Activation\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\nfrom keras.applications.inception_v3 import InceptionV3 # import inception pretrained model\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n\n'''Load Data'''\n\nif not os.path.exists('./train/'): # create train, test, and validate folders \n    \n    print(\"Creating train, validate, and test folders from database's 'train' folder\")\n    \n    # There are 10 classes (c0 ~ c9) \n    for i in range(10):\n        \n        # call the database \n        data_dir = '../input/state-farm-distracted-driver-detection/imgs/train/' + 'c' + str(i) + '/'\n\n        img_train = os.listdir(data_dir) \n        img_labels = os.listdir(data_dir)\n\n        # use train_test_split to split the data\n        x, x_test, y, y_test = train_test_split(img_train, img_labels, test_size=0.2, train_size=0.8)\n        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, train_size=0.75)\n        \n        # make the train, test, validate folders \n        os.makedirs('train/' + 'c' + str(i) + '/',exist_ok=True)\n        os.makedirs('test/' + 'c' + str(i) + '/',exist_ok=True)\n        os.makedirs('validate/' + 'c' + str(i) + '/',exist_ok=True)\n        \n        # add the images into three corresponding folders if not yet been added \n        for x in x_train:\n            if (not os.path.exists('./train/' + 'c' + str(i) + '/' + x)):\n                copy(data_dir + x, './train/' + 'c' + str(i) + '/' + x)\n\n        for x in x_test:\n            if (not os.path.exists('./test/' + 'c' + str(i) + '/' + x)):\n                copy(data_dir + x, './test/' + 'c' + str(i) + '/' + x)\n\n        for x in x_val:\n            if (not os.path.exists('./validate/' + 'c' + str(i) + '/' + x)):\n                copy(data_dir + x, './validate/' + 'c' + str(i) + '/' + x)\n\n    print(\"Data loaded\") \n\nelse: # folders exist \n    print(\"Three folders exist already\")\n    \n# paths for train, validate, test, and predict folders \n# change to your own path if necessarily \ntrainPath = './train'\nvalidatePath = './validate'\ntestPath = './test'\npredictPath = '../input/smalldataset/testdemo' # currently at small database ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T01:14:43.584214Z","iopub.execute_input":"2021-12-08T01:14:43.584603Z","iopub.status.idle":"2021-12-08T01:16:17.039551Z","shell.execute_reply.started":"2021-12-08T01:14:43.584514Z","shell.execute_reply":"2021-12-08T01:16:17.038411Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"'''Representation (dataset) of Input'''\n\n# 10 classes labeled from c0 to c9, each containing different set of images \nclassification = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\nrepresentation = {'c0': 'safe driving', 'c1': 'texting - right', 'c2': 'talking on the phone - right',\n                  'c3': 'texting - left', 'c4': 'talking on the phone - left', 'c5':'operating the radio',\n                  'c6': 'drinking', 'c7': 'reaching behind', 'c8': 'hair and makeup',\n                  'c9': 'talking to passenger'}\n\n# plot image \nplt.figure(figsize=(50, 50)) \ni = 0 # counter for making the images be aligned to each other side by side  \n\n# show one image from each class (10 images will be shown in total)\nfor classes in classification:\n    plt.subplot(1, 10, i + 1) # to plot image data from each class side by side \n    # print(trainPath + '/' + classes + '/*.jpg') # uncomment this if you want to see the name of the image \n    path = glob(trainPath + '/' + classes + '/*.jpg') # grob the image \n    openImage = cv2.imread(path[0], cv2.IMREAD_COLOR) \n    openImage = cv2.cvtColor(openImage, cv2.COLOR_BGR2RGB) \n    plt.imshow(openImage) # show the image \n    plt.title(representation[classes]) # print the title/class of the image \n    plt.axis('off')\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:17:57.984865Z","iopub.execute_input":"2021-12-08T01:17:57.985176Z","iopub.status.idle":"2021-12-08T01:17:59.273452Z","shell.execute_reply.started":"2021-12-08T01:17:57.985142Z","shell.execute_reply":"2021-12-08T01:17:59.271154Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def pretrainedModel():\n    \n    pre_trained_model = InceptionV3(input_shape = (256, 256, 3), # Shape of our input images, 3 as for RGB\n                                include_top = False, # Leave out the last fully connected layer\n                                weights = 'imagenet') \n    \n    #pre_trained_model.summary() # uncomment this if you want to print the structure of this model \n    \n    # Flatten the output layer to 1 dimension\n    flatten = layers.Flatten()(pre_trained_model.output)\n    \n    # Add a fully connected layer with 512 hidden units and ReLU activation\n    layer = layers.Dense(512, activation='relu')(flatten)\n    \n    # normalization \n    normal = layers.BatchNormalization()(layer)\n    \n    # Add a dropout rate of 0.5 \n    dropout = layers.Dropout(0.5)(normal)\n    \n    # Add a fully connected layer with 128 hidden units and ReLU activation\n    layer2 = layers.Dense(128, activation='relu')(dropout)\n    \n    # Add a dropout rate of 0.25 \n    dropout2 = layers.Dropout(0.25)(layer2)\n    \n    # Add a final softmax layer for classification\n    x = layers.Dense(10, activation='softmax')(dropout2)\n\n    model = tf.keras.Model(pre_trained_model.input, outputs=x, name='pretrainedModel')\n\n    return model\n\nprint(\"Passed function pretrained model\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:18:03.184939Z","iopub.execute_input":"2021-12-08T01:18:03.185411Z","iopub.status.idle":"2021-12-08T01:18:03.194245Z","shell.execute_reply.started":"2021-12-08T01:18:03.185375Z","shell.execute_reply":"2021-12-08T01:18:03.193457Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def createPlot(history):\n    # Plot the graph in terms of accuracy and loss \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1) \n\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\nprint(\"Passed function createPlot\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:18:06.946880Z","iopub.execute_input":"2021-12-08T01:18:06.947445Z","iopub.status.idle":"2021-12-08T01:18:06.954869Z","shell.execute_reply.started":"2021-12-08T01:18:06.947408Z","shell.execute_reply":"2021-12-08T01:18:06.954055Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"''' Data Preprocessing '''\n# all images will be rescaled by 1.0 / 255 \ntrain_datagen = ImageDataGenerator(rescale=1.0/255)\nvalidate_datagen = ImageDataGenerator(rescale=1.0/255)\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\npredict_datagen = ImageDataGenerator(rescale=1.0/255)\ntest_predict_datagen = ImageDataGenerator(rescale=1.0/255)\n\n# train using images in train folder\ntrain_generator = train_datagen.flow_from_directory( \n    trainPath, # the location of train folder\n    target_size=(256, 256), # all images will be resized to (256, 256)\n    batch_size=20,\n    color_mode=\"rgb\",\n    class_mode='categorical', # 10 classes\n    shuffle=True) # shuffle to increase the accuracy  \n\n# validate using images in validate folder\nvalidation_generator = validate_datagen.flow_from_directory(\n    validatePath, # the location of validate folder\n    target_size=(256, 256),  # all images will be resized to (256, 256)\n    batch_size=20,\n    color_mode=\"rgb\",\n    class_mode='categorical', # 10 classes\n    shuffle=True) # shuffle to increase the accuracy \n\ntest_generator = test_datagen.flow_from_directory(\n    testPath, # the location of validate folder\n    target_size=(256, 256),  # all images will be resized to (256, 256)\n    batch_size=20,\n    color_mode=\"rgb\",\n    class_mode='categorical', # 10 classes\n    shuffle=True) # shuffle to increase the accuracy  \n\n# small dataset is used for prediction for runnability  \npredict_generator = predict_datagen.flow_from_directory(\n    predictPath, # the location of prediction folder\n    target_size=(256, 256),  # all images will be resized to (256, 256)\n    batch_size=20,\n    color_mode=\"rgb\",\n    class_mode='categorical', # 10 classes\n    shuffle=False) # no point to shuffle \n\ntest_predict_generator = test_predict_datagen.flow_from_directory(\n    predictPath, # the location of prediction folder\n    target_size=(256, 256),  # all images will be resized to (256, 256)\n    batch_size=20,\n    color_mode=\"rgb\",\n    class_mode='categorical', # 10 classes\n    shuffle=False) # no point to shuffle  \n\nprint(\"Passed Data Preprocessing\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:18:09.560037Z","iopub.execute_input":"2021-12-08T01:18:09.560580Z","iopub.status.idle":"2021-12-08T01:18:11.060807Z","shell.execute_reply.started":"2021-12-08T01:18:09.560546Z","shell.execute_reply":"2021-12-08T01:18:11.059552Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"'''Model Training'''\nmodel = pretrainedModel()\n\nmodel.compile(\n    optimizer=\"rmsprop\", # rmsprop optimizer is used \n    loss='categorical_crossentropy', # 10 classes \n    metrics=['accuracy', 'AUC'])\n\nbatch_size = 512\nsteps_per_epoch = 13479 // batch_size\nvalidation_steps = 4487 //batch_size\n\nhistory = model.fit(\n    train_generator,\n    validation_data = validation_generator,\n    epochs=100, \n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps) \n    \nprint(\"Passed Model Training\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:18:14.287127Z","iopub.execute_input":"2021-12-08T01:18:14.287762Z","iopub.status.idle":"2021-12-08T01:30:15.151507Z","shell.execute_reply.started":"2021-12-08T01:18:14.287727Z","shell.execute_reply":"2021-12-08T01:30:15.150664Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#model.save(\"./model\") # save the model ","metadata":{"execution":{"iopub.status.busy":"2021-12-06T17:16:36.411462Z","iopub.execute_input":"2021-12-06T17:16:36.411767Z","iopub.status.idle":"2021-12-06T17:16:36.416342Z","shell.execute_reply.started":"2021-12-06T17:16:36.411731Z","shell.execute_reply":"2021-12-06T17:16:36.414907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saved_model = models.load_model(\"./model\") # use the save model for prediction ","metadata":{"execution":{"iopub.status.busy":"2021-12-06T03:39:46.252002Z","iopub.execute_input":"2021-12-06T03:39:46.252271Z","iopub.status.idle":"2021-12-06T03:40:01.593435Z","shell.execute_reply.started":"2021-12-06T03:39:46.252241Z","shell.execute_reply":"2021-12-06T03:40:01.592669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Evaluate Model '''\nmodel.evaluate(test_generator, batch_size=2, verbose=1)\n\n''' Plot Results '''\ncreatePlot(history)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:30:54.431232Z","iopub.execute_input":"2021-12-08T01:30:54.431571Z","iopub.status.idle":"2021-12-08T01:31:20.977657Z","shell.execute_reply.started":"2021-12-08T01:30:54.431531Z","shell.execute_reply":"2021-12-08T01:31:20.976982Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"'''Prediction using small dataset'''\n# predict using the model \npred = model.predict(predict_generator, batch_size=10) \n# pred = saved_model.predict(predict_generator, batch_size=10) # if use the saved model \npred_y = pred.argmax(axis=1)\ny_test = test_predict_generator.labels # get the true lables \nprint(\"Passed Predict\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:33:03.507871Z","iopub.execute_input":"2021-12-08T01:33:03.508814Z","iopub.status.idle":"2021-12-08T01:33:04.320684Z","shell.execute_reply.started":"2021-12-08T01:33:03.508773Z","shell.execute_reply":"2021-12-08T01:33:04.318977Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"''' Results and Evaluation '''\ndef evaluator(test_y, pred_y):\n  \n  # Confusion Matrix\n  print(\"confusion matrix: \\n\", confusion_matrix(test_y, pred_y))\n\n  # accuracy\n  print(\"accuracy: \", accuracy_score(test_y, pred_y))\n\n  # recall score\n  print(\"recall score: \",recall_score(test_y, pred_y, average='weighted'))\n\n  # precision\n  print(\"precision: \", precision_score(test_y, pred_y, average='weighted'))\n\n  # F1 score \n  print(\"F1 score: \", f1_score(test_y, pred_y, average='weighted'))\n\nevaluator(y_test, pred_y)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T01:33:06.374803Z","iopub.execute_input":"2021-12-08T01:33:06.375577Z","iopub.status.idle":"2021-12-08T01:33:06.392246Z","shell.execute_reply.started":"2021-12-08T01:33:06.375539Z","shell.execute_reply":"2021-12-08T01:33:06.391218Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Supporting Code Blocks** \n1. Delete three folders in the doc \n","metadata":{}},{"cell_type":"code","source":"'''SUPPORTING CODE BLOCKS'''\n\n# Use this to delete three folders if errors happen when creating them \n\nimport os \n\nif os.path.exists('./train/'): \n    shutil.rmtree('./train/')\n    print(\"deleted\")\n\nif os.path.exists('./test/'):\n    shutil.rmtree('./test/')\n    print(\"deleted\")\n    \nif os.path.exists('./validate/'):\n    shutil.rmtree('./validate/')\n    print(\"deleted\")\n\nif os.path.exists(\"./\"):\n    print(\"existing\")\n\nprint(\"done\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''SUPPORTING CODE BLOCKS'''\n# check if the path has train folder \nif not os.path.isdir('./output/kaggle/working/train/'):\n    print(\"files does not exist\")\n\nelif os.path.isdir('./output/kaggle/working/train/'):\n    print(\"files does exist\")\n\nelse: \n    print(\"Errors\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}